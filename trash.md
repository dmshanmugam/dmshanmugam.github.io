In this proposal, I use perspectives from women's health -- in particular, notions of underdiagnosis and uncertainty -- to rethink machine learning methodology, with the goal of building equitable algorithms in public health and healthcare. 

Each notion translates to unique technical challenges. To model and mitigate the imapct of underdiagnosis on healthcare, I propose that we develop methods grounded in statistics and machine learning to produce more accurate prevalence estimates, and devise strategies for improving prevalence estimates of these conditions. To produce useful uncertainty estimates in machine learning for healthcare, I propose that we build on work in conformal prediction, where models output *sets* of predictions with a statistical guarantee that the true prediction appears in the set. Together, my aims chart a path towards equitable machine learning in healthcare by developing new methods to safely use imperfect data and imperfect models to provide effective care. 

 and to I propose that we use methods from statistics and positive-unlabeled learning to model and mitigate the impact of underdiagnosis - i.e., diagnoses in the case of underdiagnosed conditions - on healthcare. 

Machine learning models rely heavily on accurate labels, a rarity in the case of underdiagnosed conditions. Consider intimate partner violence: it is estimated  machine learning models risk systematically denying care to patients who have historically gone undiagnosed. 

The first concerns the use of machine learning to measure and mitigate underdiagnosis of health conditions. 