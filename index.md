---
layout: default
--- 

Hi! I am a postdoc at Cornell, working with Emma Pierson and Jenna Wiens.  I completed my Ph.D. in the [Clinical and Applied Machine Learning](https://caml.csail.mit.edu/) group at MIT, where I was lucky to be advised by John Guttag. Before, I was at MIT for undergrad, where I majored in computer science with a concentration in South Asian studies. 

I work on machine learning for healthcare. My current research (often) falls into one or more of these categories:

<div style="background-color: #FFEDE0; padding: 0.75em; border-radius: 5px; border: #FFB085; margin-bottom: 0.5em; margin-top: 0em;">

<span style="color: #B84A13;"> <b> Measuring human behavior in health datasets </b> </span> <br>
Human behavior shapes the health data we use to train machine learning systems; how can we use machine learning to measure these effects? What can these models tell us about how care is currently delivered? 

<ul>
> How can we measure the extent to which diseases are underdiagnosed in different patient subgroups? (NWH 2024) <br>
> How can we measure different patterns of health access? (under review) <br>
> How can do financial incentives shape treatment decisions? (in progress)
</ul>
</div>

<div style="background-color: #FFEDE0; padding: 0.75em; border-radius: 5px; border: #FFB085; margin-bottom: 0.5em; margin-top: 0em;">

 <span style="color: #B84A13;"> <b> Learning in the absence of large, labeled datasets </b> </span>  <br>

Current approaches to updating, evaluating, and selecting models rely on a scarce resource: labeled data. How can we use alternate sources of supervision as a supplement to labeled data in post-training decision making?

<ul>
> How can we use label-preserving transformations to update models to be more accurate and robust? (ICCV 2021) <br>
> How can we use user-specified criteria to facilitate semantically-grounded, context-specific evaluation? (CHI 23) <br>
> How can we use unlabeled data to evaluate classifiers? (under review)
</ul>
</div>

<div style="background-color: #FFEDE0; padding: 0.75em; border-radius: 5px; border: #FFB085; margin-bottom: 0.5em; margin-top: 0em;">
 <span style="color: #B84A13;"> <b> Health equity </b> </span>  <br>

Can we use AI to characterize and mitigate persistent health inequities? I (and many of my co-authors) would <a url="https://arxiv.org/abs/2312.14804"> say yes</a>! 
I am especially committed to translating advances in machine learning to women's health. 

<!-- A number of open technical questions here motivate my current work,
including the scarcity of ground truth labels, and the role of predictive models in case management, particularly in the context of intimate partner violence and fertility. -->
<ul>
> What disparities might we miss without access to granular race data? (MLHC 2023) <br>
> What features are important when modeling fertility? (SR 2023) <br>
> How can we better measure the prevalence of intimate partner violence? (NWH 2024) <br>
> What new opportunities in health equity do large language models enable? (NEJM AI 2025)
</ul>
</div>

Sometimes I describe my interests as "everything but model training". This is because 1. I am impatient and 2. I believe there's a lot to gain by studying data curation and deployment.
